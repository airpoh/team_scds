{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3289c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# **Import libraries and dataset**\n",
    "\n",
    "# %%\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset with spam column\n",
    "df = pd.read_csv(\"combined_dataset_with_spam.csv\")\n",
    "\n",
    "print(\"‚úÖ Dataset loaded\")\n",
    "print(\"üìä Shape:\", df.shape)\n",
    "print(\"üìù Features:\", df.columns.tolist())\n",
    "print(df.head(3))\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# **Convert Dates**\n",
    "\n",
    "# %%\n",
    "# Convert to datetime\n",
    "df[\"publishedAt\"] = pd.to_datetime(df[\"publishedAt\"], errors=\"coerce\")\n",
    "\n",
    "# Extract year-week\n",
    "df[\"year_week\"] = df[\"publishedAt\"].dt.strftime(\"%Y-%U\")\n",
    "\n",
    "print(df[[\"publishedAt\", \"year_week\"]].head())\n",
    "\n",
    "\n",
    "# %%\n",
    "print(df[\"videoId\"].dtype)   # should be int64 or object\n",
    "print(df[\"videoId\"].nunique())\n",
    "print(df[\"videoId\"].head(10))\n",
    "\n",
    "# %% [markdown]\n",
    "# **Aggregate Engagement**\n",
    "\n",
    "# %% [markdown]\n",
    "# engagement=likeCount+1√ó(comment)\n",
    "\n",
    "# %%\n",
    "# Engagement = likes + 1 per comment\n",
    "df[\"engagement\"] = df[\"likeCount\"].fillna(0) + 1  \n",
    "\n",
    "# Group by videoId + week safely\n",
    "weekly = (\n",
    "    df.groupby([\"videoId\", \"year_week\"], as_index=False)\n",
    "      .agg(\n",
    "          total_comments=(\"commentId\", \"count\"),\n",
    "          total_likes=(\"likeCount\", \"sum\"),\n",
    "          total_engagement=(\"engagement\", \"sum\"),\n",
    "          spam_ratio=(\"spam\", \"mean\")   # average spam flag = spam ratio\n",
    "      )\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Weekly engagement dataset created\")\n",
    "print(\"üìä Shape:\", weekly.shape)\n",
    "print(\"\\nüîé Preview:\")\n",
    "print(weekly.head(10))\n",
    "print(\"\\nUnique videoIds in weekly:\", weekly[\"videoId\"].nunique())\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# **Create Features and Target (Shifted Next-Week SoE)**\n",
    "\n",
    "# %%\n",
    "# Sort by videoId and week for shifting\n",
    "weekly = weekly.sort_values([\"videoId\", \"year_week\"])\n",
    "\n",
    "# Create next-week target (SoE)\n",
    "weekly[\"next_week_engagement\"] = (\n",
    "    weekly.groupby(\"videoId\")[\"total_engagement\"].shift(-1)\n",
    ")\n",
    "\n",
    "# Drop rows where next_week_engagement is NaN (last week per video)\n",
    "weekly = weekly.dropna(subset=[\"next_week_engagement\"])\n",
    "\n",
    "print(\"‚úÖ Target created\")\n",
    "print(\"üìä Shape:\", weekly.shape)\n",
    "print(weekly.head(10))\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# **Feature Engineering**\n",
    "\n",
    "# %%\n",
    "features = [\"total_comments\", \"total_likes\", \"total_engagement\", \"spam_ratio\"]\n",
    "target = \"next_week_engagement\"\n",
    "\n",
    "X = weekly[features]\n",
    "y = weekly[target]\n",
    "\n",
    "print(\"‚úÖ Features and target prepared\")\n",
    "print(\"üìù Features:\", features)\n",
    "print(\"üéØ Target:\", target)\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# **Train/Test Split**\n",
    "\n",
    "# %%\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Data split complete\")\n",
    "print(\"üìä Train shape:\", X_train.shape)\n",
    "print(\"üìä Test shape:\", X_test.shape)\n",
    "\n",
    "# %% [markdown]\n",
    "# **Exploratory Plots**\n",
    "\n",
    "# %%\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1Ô∏è‚É£ Engagement distribution\n",
    "plt.figure(figsize=(8,5))\n",
    "weekly[\"total_engagement\"].hist(bins=50)\n",
    "plt.xlabel(\"Total Engagement (per video-week)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of Weekly Engagement\")\n",
    "plt.show()\n",
    "\n",
    "# 2Ô∏è‚É£ Spam ratio distribution\n",
    "plt.figure(figsize=(8,5))\n",
    "weekly[\"spam_ratio\"].hist(bins=50, color=\"orange\")\n",
    "plt.xlabel(\"Spam Ratio\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of Spam Ratios per Week\")\n",
    "plt.show()\n",
    "\n",
    "# 3Ô∏è‚É£ Example video trend\n",
    "example_video = weekly[\"videoId\"].iloc[0]   # pick the first videoId\n",
    "video_trend = weekly[weekly[\"videoId\"] == example_video]\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(video_trend[\"year_week\"], video_trend[\"total_engagement\"], marker=\"o\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel(\"Year-Week\")\n",
    "plt.ylabel(\"Engagement\")\n",
    "plt.title(f\"Engagement Trend for Video {example_video}\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# **Train LightGBM Model**\n",
    "\n",
    "# %%\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "# -----------------------------\n",
    "# 1Ô∏è‚É£ Create target = next week's engagement\n",
    "# -----------------------------\n",
    "weekly = weekly.sort_values([\"videoId\", \"year_week\"])\n",
    "weekly[\"next_engagement\"] = weekly.groupby(\"videoId\")[\"total_engagement\"].shift(-1)\n",
    "\n",
    "# Drop rows where next_engagement is missing (last week per video)\n",
    "weekly = weekly.dropna(subset=[\"next_engagement\"])\n",
    "\n",
    "print(\"‚úÖ Target column created\")\n",
    "print(\"üìä Shape after shift:\", weekly.shape)\n",
    "\n",
    "# -----------------------------\n",
    "# 2Ô∏è‚É£ Select features & target\n",
    "# -----------------------------\n",
    "features = [\"total_comments\", \"total_likes\", \"total_engagement\", \"spam_ratio\"]\n",
    "target = \"next_engagement\"\n",
    "\n",
    "X = weekly[features]\n",
    "y = weekly[target]\n",
    "\n",
    "# -----------------------------\n",
    "# 3Ô∏è‚É£ Train-test split\n",
    "# -----------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# 4Ô∏è‚É£ Convert to LightGBM Dataset\n",
    "# -----------------------------\n",
    "lgb_train = lgb.Dataset(X_train, label=y_train)\n",
    "lgb_val   = lgb.Dataset(X_test, label=y_test)\n",
    "\n",
    "# -----------------------------\n",
    "# 5Ô∏è‚É£ Parameters\n",
    "# -----------------------------\n",
    "params = {\n",
    "    \"objective\": \"regression\",\n",
    "    \"metric\": \"rmse\",\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"num_leaves\": 31,\n",
    "    \"seed\": 42,\n",
    "    \"verbosity\": -1\n",
    "}\n",
    "\n",
    "# -----------------------------\n",
    "# 6Ô∏è‚É£ Train model\n",
    "# -----------------------------\n",
    "model = lgb.train(\n",
    "    params,\n",
    "    lgb_train,\n",
    "    valid_sets=[lgb_train, lgb_val],\n",
    "    num_boost_round=1000,\n",
    "    callbacks=[lgb.early_stopping(stopping_rounds=50)]\n",
    ")\n",
    "\n",
    "print(\"‚úÖ LightGBM training complete\")\n",
    "\n",
    "# -----------------------------\n",
    "# 7Ô∏è‚É£ Evaluate model\n",
    "# -----------------------------\n",
    "y_pred = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(f\"üìâ RMSE: {rmse:.2f}\")\n",
    "print(f\"üìâ MAE: {mae:.2f}\")\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# **SHAP Explainability**\n",
    "\n",
    "# %%\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -----------------------------\n",
    "# 1Ô∏è‚É£ Initialize SHAP explainer\n",
    "# -----------------------------\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "print(\"‚úÖ SHAP values computed\")\n",
    "\n",
    "# -----------------------------\n",
    "# 2Ô∏è‚É£ Feature importance summary plot\n",
    "# -----------------------------\n",
    "plt.figure()\n",
    "shap.summary_plot(shap_values, X_test, feature_names=features)\n",
    "\n",
    "# -----------------------------\n",
    "# 3Ô∏è‚É£ Feature importance bar chart\n",
    "# -----------------------------\n",
    "plt.figure()\n",
    "shap.summary_plot(shap_values, X_test, feature_names=features, plot_type=\"bar\")\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# **Save Model & SHAP Results**\n",
    "\n",
    "# %%\n",
    "import joblib\n",
    "import shap\n",
    "import pandas as pd\n",
    "\n",
    "# -----------------------------\n",
    "# 1Ô∏è‚É£ Save trained model\n",
    "# -----------------------------\n",
    "joblib.dump(model, \"lgbm_soe_model.pkl\")\n",
    "print(\"‚úÖ Model saved as lgbm_soe_model.pkl\")\n",
    "\n",
    "# -----------------------------\n",
    "# 2Ô∏è‚É£ Save SHAP values (optional, can be heavy)\n",
    "# -----------------------------\n",
    "shap_values_df = pd.DataFrame(shap_values, columns=features)\n",
    "shap_values_df.to_csv(\"shap_values.csv\", index=False)\n",
    "print(\"‚úÖ SHAP values saved as shap_values.csv\")\n",
    "\n",
    "# -----------------------------\n",
    "# 3Ô∏è‚É£ Save feature importance\n",
    "# -----------------------------\n",
    "importance_df = pd.DataFrame({\n",
    "    \"feature\": features,\n",
    "    \"importance\": model.feature_importance()\n",
    "}).sort_values(by=\"importance\", ascending=False)\n",
    "\n",
    "importance_df.to_csv(\"feature_importance.csv\", index=False)\n",
    "print(\"‚úÖ Feature importance saved as feature_importance.csv\")\n",
    "\n",
    "# -----------------------------\n",
    "# 4Ô∏è‚É£ Reload model later\n",
    "# -----------------------------\n",
    "loaded_model = joblib.load(\"lgbm_soe_model.pkl\")\n",
    "print(\"‚úÖ Model reloaded, ready for new predictions\")\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# **Prediction Pipeline**\n",
    "\n",
    "# %%\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# -----------------------------\n",
    "# 1Ô∏è‚É£ Load model & feature list\n",
    "# -----------------------------\n",
    "model = joblib.load(\"lgbm_soe_model.pkl\")\n",
    "features = [\"total_comments\", \"total_likes\", \"total_engagement\", \"spam_ratio\"]\n",
    "\n",
    "print(\"‚úÖ Model loaded, ready for predictions\")\n",
    "\n",
    "# -----------------------------\n",
    "# 2Ô∏è‚É£ Example: New incoming video engagement data\n",
    "# -----------------------------\n",
    "new_data = pd.DataFrame([\n",
    "    {\n",
    "        \"total_comments\": 120,\n",
    "        \"total_likes\": 450,\n",
    "        \"total_engagement\": 570,  # likes + comments\n",
    "        \"spam_ratio\": 0.25\n",
    "    },\n",
    "    {\n",
    "        \"total_comments\": 300,\n",
    "        \"total_likes\": 1200,\n",
    "        \"total_engagement\": 1500,\n",
    "        \"spam_ratio\": 0.10\n",
    "    }\n",
    "])\n",
    "\n",
    "print(\"üîé New data to predict:\")\n",
    "print(new_data)\n",
    "\n",
    "# -----------------------------\n",
    "# 3Ô∏è‚É£ Predict next-week SoE\n",
    "# -----------------------------\n",
    "predictions = model.predict(new_data[features])\n",
    "\n",
    "new_data[\"predicted_next_week_SoE\"] = predictions\n",
    "\n",
    "print(\"\\n‚úÖ Predictions complete\")\n",
    "print(new_data)\n",
    "\n",
    "\n",
    "# %%\n",
    "print(weekly.columns.tolist())\n",
    "\n",
    "\n",
    "# %%\n",
    "# Create a SoE column as normalized engagement\n",
    "weekly['SoE'] = weekly['total_engagement'] / weekly['total_engagement'].max()\n",
    "\n",
    "# Select features\n",
    "auth_features = weekly[['SoE', 'spam_ratio']].copy()\n",
    "\n",
    "# Fill NaN\n",
    "auth_features = auth_features.fillna(0)\n",
    "\n",
    "# Train Isolation Forest\n",
    "from sklearn.ensemble import IsolationForest\n",
    "iso = IsolationForest(n_estimators=200, contamination=0.05, random_state=42)\n",
    "iso.fit(auth_features)\n",
    "\n",
    "# Predict authenticity\n",
    "weekly['authenticity_flag'] = iso.predict(auth_features)\n",
    "weekly['authenticity_score'] = weekly['authenticity_flag'].map({1: 'Authentic', -1: 'Suspicious'})\n",
    "\n",
    "# Preview results\n",
    "print(weekly[['videoId', 'SoE', 'spam_ratio', 'authenticity_score']].head())\n",
    "\n",
    "\n",
    "# %%\n",
    "suspicious_videos = weekly[weekly['authenticity_score'] == 'Suspicious']\n",
    "print(f\"‚ö†Ô∏è Number of suspicious videos: {len(suspicious_videos)}\")\n",
    "suspicious_videos[['videoId', 'SoE', 'spam_ratio', 'authenticity_score']].head()\n",
    "\n",
    "\n",
    "# %%\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.scatterplot(\n",
    "    data=weekly,\n",
    "    x='SoE',\n",
    "    y='spam_ratio',\n",
    "    hue='authenticity_score',\n",
    "    palette={'Authentic':'green', 'Suspicious':'red'},\n",
    "    alpha=0.7\n",
    ")\n",
    "plt.title('Fake Engagement Insurance: SoE vs Spam Ratio')\n",
    "plt.xlabel('Share of Engagement (SoE)')\n",
    "plt.ylabel('Spam Ratio')\n",
    "plt.legend(title='Authenticity')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# %%\n",
    "weekly['suspicion_score'] = 1 - (weekly['authenticity_flag'] + 1)/2  # 1 = suspicious, 0 = authentic\n",
    "top_suspicious = weekly.sort_values(by='suspicion_score', ascending=False).head(10)\n",
    "print(top_suspicious[['videoId', 'SoE', 'spam_ratio', 'authenticity_score']])\n",
    "\n",
    "\n",
    "# %%\n",
    "import joblib\n",
    "joblib.dump(iso, \"iso_model.pkl\")\n",
    "print(\"‚úÖ Isolation Forest model saved as iso_model.pkl\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
